{"cells":[{"cell_type":"markdown","metadata":{"id":"459afb11-0cdf-4f80-accc-1526e1519734"},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","metadata":{"id":"c3ec9089-324d-4c7a-a9d7-922e8b28e24b"},"source":["# **Integrating Word2Vec**\n"]},{"cell_type":"markdown","metadata":{"id":"63d32a09-355e-4579-bb1b-c650a0ec8586"},"source":["Estimated time needed: **60** minutes\n"]},{"cell_type":"markdown","metadata":{"id":"b82098ae-ba46-4a93-9288-043f74b0c0a6"},"source":["\"The worlds most valuable resource is no longer oil, but data\", you hear that a lot, but did you ever wonder what that really means. Through word2vec, you'll unlock the power of words in large datasets, providing you with the tools to tackle real-world problems effectively.\n"," <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/data_oil.png\" alt=\"new oild\">\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"d1c7bfcc-5c06-4bbe-9852-4e57ba07f201"},"source":["Here, you will be introduced to the Skip-gram and CBOW models, teaching how to build and apply these for text classification in PyTorch. You'll also incorporate pretrained GloVe embeddings to enhance the models. An optional section on advanced embedding applications is available for further exploration. By the end of this lab, you'll be adept at using word embeddings for natural language processing (NLP) tasks.\n"]},{"cell_type":"markdown","metadata":{"id":"5e715aaf-2d99-4155-88da-79219c760128"},"source":["## __Table of Contents__\n","\n","<ol>\n","    <li><a href=\"#Objectives\">Objectives</a></li>\n","    <li>\n","        <a href=\"#Setup\">Setup</a>\n","        <ol>\n","            <li><a href=\"#Installing-required-libraries\">Installing required libraries</a></li>\n","            <li><a href=\"#Importing-Required-Libraries\">Importing required libraries</a></li>\n","        </ol>\n","    </li>\n","    <li>\n","        <a href=\"#Background\">Background</a>\n","        <ol>\n","            <li><a href=\"#Word2Vec\">Word2Vec</a></li>\n","            <li><a href=\"#GloVe-(Optional)\">GloVe (Optional)</a></li>\n","        </ol>\n","    </li>\n","    <li><a href=\"#Create-and-train-word2vec-models\">Create and train word2vec models</a></li>\n","        <ol>\n","            <li><a href=\"#Continuous-Bag-of-Words-(CBOW)\">Continuous Bag of Words (CBOW)</a></li>\n","            <li><a href=\"#Skip-gram-model\">Skip-gram model</a></li>\n","        </ol>\n","    <li><a href=\"#Applying-pretrained-word-embeddings-(optional)\">Applying pretrained word embeddings (optional)</a></li>\n","        <ol>\n","            <li><a href=\"#Load-Stanford-GloVe-model\">Load Stanford GloVe model</a></li>\n","            <li><a href=\"#Train-a-word2vec-model-from-gensim\">Train a word2vec model from gensim</a></li>\n","        </ol>\n","     <li><a href=\"#Text-classification-using-pretrained-word-embeddings\">Text classification using pretrained word embeddings</a>\n","</ol>\n"]},{"cell_type":"markdown","metadata":{"id":"8589ee13-af7c-4317-aeac-943fbf9d13f2"},"source":["## Objectives\n","\n","After completing this lab you will be able to:\n","- Comprehend word embedding with word2vec.\n","- Create and train basic word2vec models using CBOW and Skip-gram architectures.\n","- Get pretrained large embedding models and generate word embeddings with them.\n","- Train a word2vec model on a domain-specific data.\n"]},{"cell_type":"markdown","metadata":{"id":"d67d1081-2532-4e33-b49e-257db60c9ab6"},"source":["----\n"]},{"cell_type":"markdown","metadata":{"id":"acca7b22-5999-4bb9-aead-3911157a0b8f"},"source":["## Setup\n"]},{"cell_type":"markdown","metadata":{"id":"f320a463-00e4-43d7-b58d-a82db250d7a6"},"source":["For this lab, you will be using the following libraries:\n","\n","*   [`torch`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for building NN models and preparing the data.\n","*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n","*   [`gensim`](https://pypi.org/project/gensim/) for word2vec pretrained models.\n","*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for visualizing the data.\n","*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n"]},{"cell_type":"markdown","metadata":{"id":"59327fd5-92d1-455b-8f87-3288de032c30"},"source":["### Installing required libraries\n","<h2 style=\"color:red;\">After installing the libraries below please RESTART THE KERNEL and run all cells.</h2>\n"]},{"cell_type":"markdown","metadata":{"id":"52c65743-527c-4df5-895f-8455026fdf13"},"source":["The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"]},{"cell_type":"markdown","metadata":{"id":"952da389-c466-4364-886d-6c0514fcf94d"},"source":["### Importing required libraries\n","\n","_It is recommended that you import all required libraries in one place (here):_\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8b3f8d67-f6d9-4ee4-be5a-161ea59e3ea5","executionInfo":{"status":"ok","timestamp":1738419722242,"user_tz":-300,"elapsed":11115,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}},"outputId":"b547b90b-4271-4ddd-d030-b5c16fe22551"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.manifold import TSNE\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import gensim\n","from gensim.models import Word2Vec\n","\n","import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt_tab')\n","\n","#Suupress warnings\n","def warn(*args,**kwargs):\n","  pass\n","import warnings\n","warnings.warn=warn\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"3012dbcc-d2c1-45ca-bbb5-6f90bea3744f"},"source":["Define a function to plot word embeddings in a 2d space.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"39c60097-6146-4d1e-b3c5-a7129e9b3f11","executionInfo":{"status":"ok","timestamp":1738419751581,"user_tz":-300,"elapsed":405,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}}},"outputs":[],"source":["def plot_embeddings(word_embeddings, vocab):\n","    tsne = TSNE(n_components=2, random_state=0)\n","    word_embeddings_2d = tsne.fit_transform(word_embeddings)\n","\n","    # Plotting the results with labels from vocab\n","    plt.figure(figsize=(15, 15))\n","    for word, idx in vocab.items():  # vocab is a dictionary now\n","        plt.scatter(word_embeddings_2d[idx, 0], word_embeddings_2d[idx, 1])\n","        plt.annotate(word, (word_embeddings_2d[idx, 0], word_embeddings_2d[idx, 1]))\n","\n","    plt.xlabel(\"t-SNE component 1\")\n","    plt.ylabel(\"t-SNE component 2\")\n","    plt.title(\"Word Embeddings visualized with t-SNE\")\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"911667b6-5e8d-4ea1-92c9-ea6434d84171"},"source":["Define a function that returns similar words to a specific word by calculating Cosine distance.\n"]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","\n","def find_similar_words(word, word_embeddings, top_k=5):\n","    # Check if the word exists in the embeddings dictionary\n","    if word not in word_embeddings:\n","        print(\"Word not found in embeddings\")\n","        return []\n","\n","    # Get the embedding for the given word and convert it to a tensor\n","    target_embedding = torch.tensor(word_embeddings[word])\n","\n","    # Dictionary to store cosine similarities of all words with the target word\n","    similarities = {}\n","\n","    # Iterate through all words and their embeddings\n","    for w, embedding in word_embeddings.items():\n","        if w != word:  # Skip the target word itself\n","            embedding_tensor = torch.tensor(embedding)  # Convert embedding to tensor\n","\n","            # Compute cosine similarity between target word and the current word\n","            similarity = torch.dot(target_embedding, embedding_tensor) / (\n","                torch.norm(target_embedding) * torch.norm(embedding_tensor)\n","            )\n","\n","            # Store similarity score in the dictionary\n","            similarities[w] = similarity.item()\n","\n","    # Sort the words based on similarity scores in descending order\n","    sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n","\n","    # Extract the top k most similar words\n","    most_similar_words = [w for w, _ in sorted_similarities[:top_k]]\n","\n","    return most_similar_words\n"],"metadata":{"id":"lSUwt3DOWbzo","executionInfo":{"status":"ok","timestamp":1738419755389,"user_tz":-300,"elapsed":411,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8a986673-0268-4dcc-91ed-cc434b81f1b9"},"source":["Define a function that trains word2vec model on toy data.\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"21234e2d-0b48-4ff1-8cd0-f8a229e43905","executionInfo":{"status":"ok","timestamp":1738419760606,"user_tz":-300,"elapsed":425,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}}},"outputs":[],"source":["def train_model(model, dataloader, criterion, optimizer, num_epochs=100):\n","    \"\"\"\n","    Train the model for the specified number of epochs.\n","\n","    Args:\n","        model: The PyTorch model to be trained.\n","        dataloader: DataLoader providing data for training.\n","        criterion: Loss function.\n","        optimizer: Optimizer for updating model's weights.\n","        num_epochs: Number of epochs to train the model for.\n","\n","    Returns:\n","        model: The trained model.\n","        epoch_losses: List of average losses for each epoch.\n","    \"\"\"\n","\n","    # List to store average loss for each epoch\n","    epoch_losses = []\n","\n","    # Loop over the specified number of epochs\n","    for epoch in tqdm(range(num_epochs), desc=\"Training Progress\"):\n","        running_loss = 0.0  # Initialize running loss for the current epoch\n","\n","        # Iterate over batches from the dataloader\n","        for idx, samples in enumerate(dataloader):\n","            optimizer.zero_grad()  # Reset gradients before each batch\n","\n","            # Check if the model contains an EmbeddingBag layer\n","            if any(isinstance(module, nn.EmbeddingBag) for _, module in model.named_modules()):\n","                target, context, offsets = samples  # Unpack batch samples\n","                predicted = model(context, offsets)  # Forward pass\n","\n","            # Check if the model contains an Embedding layer\n","            elif any(isinstance(module, nn.Embedding) for _, module in model.named_modules()):\n","                target, context = samples  # Unpack batch samples\n","                predicted = model(context)  # Forward pass\n","\n","            loss = criterion(predicted, target)  # Compute loss\n","            loss.backward()  # Backpropagate the gradients\n","\n","            # Clip gradients to prevent exploding gradients\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n","            optimizer.step()  # Update model weights\n","\n","            running_loss += loss.item()  # Accumulate loss\n","\n","        # Compute average loss for the epoch and store it\n","        epoch_losses.append(running_loss / len(dataloader))\n","\n","    return model, epoch_losses\n"]},{"cell_type":"markdown","metadata":{"id":"63403bc6-db06-4a7b-b1c3-214b32ccb8d8"},"source":["# Background\n","\n","## Word2Vec\n","\n","Word2Vec is a family of  methods that transforms words into number vectors, positioning similar words close together in a space defined by these numbers. This way, you can quantify and analyze word relationships mathematically. For instance, words like \"cat\" and \"kitten\" or \"cat\" and \"dog\" have vectors that are close to each other, while a word like \"book\" is positioned further away in this vector space.\n","\n","\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/Words.png\" alt=\"Word2Vec example\" class=\"bg-primary\" width=\"400px\">\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2ea68056-de20-48d0-bd0f-4a1e661d55d3"},"source":["In this lab session, you'll concentrate on mastering Skip-gram and Continuous Bag of Words (CBOW) models, which are essential precursors to grasping the principles of generative modeling. Additionally, you'll explore the GloVe model, and an **optional** summary will be provided to enhance your understanding of its application in natural language processing.\n","## GloVe (Optional)\n","\n","\n","\n","GloVe, on the other hand, is another popular algorithm for learning word embeddings. It stands for Global Vectors for Word Representation. Unlike word2vec, which is based on predicting context/target words, GloVe focuses on capturing the global word co-occurrence statistics from the entire corpus. It constructs a co-occurrence matrix that represents how often words appear together in the text. The matrix is then factorized to obtain the word embeddings. For example, if \"Man\" and \"King\" co-occure many times, their vectors will be simialr.\n","\n","The GloVe model follows a fundamental approach by constructing a large word-context co-occurrence matrix that contains pairs of (word, context). Each entry in this matrix represents the frequency of a word occurring within a given context, which can be a sequence of words. The objective of the model is to utilize matrix factorization techniques to approximate this co-occurrence matrix. The process is illustrated in the following diagram:\n","\n","1. Create a word-context co-occurrence matrix: The model begins by generating a matrix that captures the co-occurrence information of words and their surrounding contexts. Each element in the matrix represents how often a specific word and context pair co-occur in the training data.\n","\n","2. Apply matrix factorization: Next, the GloVe model applies matrix factorization methods to approximate the word-context co-occurrence matrix. The goal is to decompose the original matrix into lower-dimensional representations that capture the semantic relationships between words and contexts.\n","\n","3. Obtain word and context embeddings: By factorizing the co-occurrence matrix, the model obtains word and context embeddings. These embeddings are numerical representations that encode the semantic meaning and relationships of words and contexts.\n","\n","To accomplish this, you can usually begin by initializing WF (Word-Feature matrix) and FC (Feature-Context matrix) with random weights.You will then perform a multiplication operation between these matrices to obtain WC' (an approximation of WC), and assess its similarity to WC. This process is repeated multiple times using Stochastic Gradient Descent (SGD) to minimize the error(WC'-WC).\n","\n","Once the training is complete, the resulting Word-Feature matrix (WF) provides you with word embeddings or vector representations for each word(the green vector in the diagram). The dimensionality of the embedding vectors can be predetermined by setting the value of F to a specific number of dimensions, allowing for a compact representation of the word semantics.\n","\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/matrix%20fact.png\" alt=\"Co-occurence matrix\" class=\"bg-primary\" width=\"600px\">\n","\n","The key advantage of GloVe is that it can incorporate both global statistics and local context information. This results in word embeddings that not only capture the semantic relationships between words but also preserve certain syntactic relationships.\n"]},{"cell_type":"markdown","metadata":{"id":"7b7c6817-92b4-4be3-aa8c-e9cb99767754"},"source":["# Create and train word2vec models\n","Now it's time to get your hands dirty. Let's start with a very simple implementation of word2vec to train it on a toy dataset:\n"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"57a16205-b88d-4c0e-b0e1-8a14c644b0e8","executionInfo":{"status":"ok","timestamp":1738421350919,"user_tz":-300,"elapsed":423,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}}},"outputs":[],"source":["toy_data = \"\"\"I wish I was little bit taller\n","I wish I was a baller\n","She wore a small black dress to the party\n","The dog chased a big red ball in the park\n","He had a huge smile on his face when he won the race\n","The tiny kitten played with a fluffy toy mouse\n","The team celebrated their victory with a grand parade\n","She bought a small, delicate necklace for her sister\n","The mountain peak stood majestic and tall against the clear blue sky\n","The toddler took small, careful steps as she learned to walk\n","The house had a spacious backyard with a big swimming pool\n","He felt a sense of accomplishment after completing the challenging puzzle\n","The chef prepared a delicious, flavorful dish using fresh ingredients\n","The children played happily in the small, cozy room\n","The book had an enormous impact on readers around the world\n","The wind blew gently, rustling the leaves of the tall trees\n","She painted a beautiful, intricate design on the small canvas\n","The concert hall was filled with thousands of excited fans\n","The garden was adorned with colorful flowers of all sizes\n","I hope to achieve great success in my chosen career path\n","The skyscraper towered above the city, casting a long shadow\n","He gazed in awe at the breathtaking view from the mountaintop\n","The artist created a stunning masterpiece with bold brushstrokes\n","The baby took her first steps, a small milestone that brought joy to her parents\n","The team put in a tremendous amount of effort to win the championship\n","The sun set behind the horizon, painting the sky in vibrant colors\n","The professor gave a fascinating lecture on the history of ancient civilizations\n","The house was filled with laughter and the sound of children playing\n","She received a warm, enthusiastic welcome from the audience\n","The marathon runner had incredible endurance and determination\n","The child's eyes sparkled with excitement upon opening the gift\n","The ship sailed across the vast ocean, guided by the stars\n","The company achieved remarkable growth in a short period of time\n","The team worked together harmoniously to complete the project\n","The puppy wagged its tail, expressing its happiness and affection\n","She wore a stunning gown that made her feel like a princess\n","The building had a grand entrance with towering columns\n","The concert was a roaring success, with the crowd cheering and clapping\n","The baby took a tiny bite of the sweet, juicy fruit\n","The athlete broke a new record, achieving a significant milestone in her career\n","The sculpture was a masterpiece of intricate details and craftsmanship\n","The forest was filled with towering trees, creating a sense of serenity\n","The children built a small sandcastle on the beach, their imaginations running wild\n","The mountain range stretched as far as the eye could see, majestic and awe-inspiring\n","The artist's brush glided smoothly across the canvas, creating a beautiful painting\n","She received a small token of appreciation for her hard work and dedication\n","The orchestra played a magnificent symphony that moved the audience to tears\n","The flower bloomed in vibrant colors, attracting butterflies and bees\n","The team celebrated their victory with a big, extravagant party\n","The child's laughter echoed through the small room, filling it with joy\n","The sunflower stood tall, reaching for the sky with its bright yellow petals\n","The city skyline was dominated by tall buildings and skyscrapers\n","The cake was adorned with a beautiful, elaborate design for the special occasion\n","The storm brought heavy rain and strong winds, causing widespread damage\n","The small boat sailed peacefully on the calm, glassy lake\n","The artist used bold strokes of color to create a striking and vivid painting\n","The couple shared a passionate kiss under the starry night sky\n","The mountain climber reached the summit after a long and arduous journey\n","The child's eyes widened in amazement as the magician performed his tricks\n","The garden was filled with the sweet fragrance of blooming flowers\n","The basketball player made a big jump and scored a spectacular slam dunk\n","The cat pounced on a small mouse, displaying its hunting instincts\n","The mansion had a grand entrance with a sweeping staircase and chandeliers\n","The raindrops fell gently, creating a rhythmic patter on the roof\n","The baby took a big step forward, encouraged by her parents' applause\n","The actor delivered a powerful and emotional performance on stage\n","The butterfly fluttered its delicate wings, mesmerizing those who watched\n","The company launched a small-scale advertising campaign to test the market\n","The building was constructed with strong, sturdy materials to withstand earthquakes\n","The singer's voice was powerful and resonated throughout the concert hall\n","The child built a massive sandcastle with towers, moats, and bridges\n","The garden was teeming with a variety of small insects and buzzing bees\n","The athlete's muscles were well-developed and strong from years of training\n","The sun cast long shadows as it set behind the mountains\n","The couple exchanged heartfelt vows in a beautiful, intimate ceremony\n","The dog wagged its tail vigorously, a sign of excitement and happiness\n","The baby let out a tiny giggle, bringing joy to everyone around\"\"\"\n"]},{"cell_type":"markdown","metadata":{"id":"7c52f3ab-cc6a-47e5-afee-f63194c9f19c"},"source":["Next, you'll prepare data by tokenizing it and creating a vocabulary from data.\n"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"06054213-994d-4000-87a8-bebdfd2834b4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738421353583,"user_tz":-300,"elapsed":425,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}},"outputId":"0df3b68f-54aa-439d-caf7-4b8b4be70345"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["from collections import Counter\n","from itertools import chain\n","import nltk\n","nltk.download('punkt')  # Ensure NLTK tokenizer is available\n","from nltk.tokenize import word_tokenize\n","\n","tokenizer = word_tokenize  # Use NLTK's word tokenizer\n","\n","# Step 2: Function to tokenize sentences\n","def tokenize_data(sentences):\n","    \"\"\"\n","    Tokenizes each sentence in the given list of sentences.\n","\n","    Args:\n","        sentences (list): List of sentences to tokenize.\n","\n","    Returns:\n","        list: List of tokenized words from each sentence.\n","    \"\"\"\n","    return [tokenizer(sentence) for sentence in sentences]\n","\n","# Tokenizing toy data\n","tokenized_toy_data = tokenize_data(toy_data)\n","\n","# Flatten the tokenized data to create a single list of words\n","flat_tokenized_data = list(chain(*tokenized_toy_data))\n","\n","# Step 3: Build vocabulary from tokenized data with <unk> (unknown) token\n","counter = Counter(flat_tokenized_data)  # Count word occurrences\n","vocab = {word: idx for idx, (word, _) in enumerate(counter.most_common(), start=1)}\n","vocab[\"<unk>\"] = 0  # Assign index 0 to unknown token"]},{"cell_type":"markdown","metadata":{"id":"a8fd5435-66ba-428f-9682-3197495076a8"},"source":["Let's check how a sentence looks like after tokenization and numericalization:\n"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"cd968f42-b4f4-4d10-9ac2-fc83f1d71090","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738421365792,"user_tz":-300,"elapsed":404,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}},"outputId":"971fc933-eabd-4fff-d068-992483436f4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Encoded sample: [30, 0, 30, 0, 2, 0]\n"]}],"source":["# Test a sample sentence\n","sample_sentence = \"I wish I was a baller\"\n","\n","# Tokenize the sample sentence using NLTK\n","tokenized_sample = tokenizer(sample_sentence)\n","\n","# Encode the tokenized words using the vocabulary\n","# If a word is not in the vocabulary, use the index for '<unk>'\n","encoded_sample = [vocab.get(token, vocab[\"<unk>\"]) for token in tokenized_sample]\n","\n","# Print the encoded representation of the sample sentence\n","print(\"Encoded sample:\", encoded_sample)"]},{"cell_type":"markdown","metadata":{"id":"1dbbaa09-80e1-4f23-b9ae-b2c3196afa04"},"source":["You can write a fuction to apply numericalization on all tokens:\n"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"3d577d5a-9ad9-44e8-a222-f8862feedf43","executionInfo":{"status":"ok","timestamp":1738421383751,"user_tz":-300,"elapsed":402,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}}},"outputs":[],"source":["# Define a text pipeline for encoding\n","def text_pipeline(tokens):\n","    return [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]"]},{"cell_type":"markdown","metadata":{"id":"48e04b1d-c5c7-49a9-9c73-f1906e4a6f2e"},"source":["Let's delve into two main architectures for training word2vec embeddings:\n"]},{"cell_type":"markdown","metadata":{"id":"725785c5-8ad6-4a22-9a16-42b72623d36e"},"source":["## Continuous Bag of Words (CBOW)\n","\n","For the Continuous Bag of Words (CBOW) model, use a \"context\" to predict a target word. The \"context\" is typically a set of surrounding words. For example, if your context window is of size 2, then you take two words before and two words after the target word as context. The target word is in red and the context is in blue:\n"]},{"cell_type":"markdown","metadata":{"id":"bc5ffc7c-b378-4efb-b621-be9ba02a7886"},"source":["<table border=\"1\">\n","    <tr>\n","        <th>Time Step</th>\n","        <th>Phrase</th>\n","    </tr>\n","    <tr>\n","        <td>1</td>\n","        <td><span style=\"color:blue;\">I wish</span> <span style=\"color:red;\">I</span> <span style=\"color:blue;\">was  little </span></td>\n","    </tr>\n","    <tr>\n","        <td>2</td>\n","        <td><span style=\"color:blue;\">wish I</span> <span style=\"color:red;\">was</span> <span style=\"color:blue;\">little bit </span></td>\n","    </tr>\n","    <tr>\n","        <td>3</td>\n","        <td><span style=\"color:blue;\">I was</span> <span style=\"color:red;\">little</span> <span style=\"color:blue;\">  bit taller</span></td>\n","    </tr>\n","    <tr>\n","        <td>4</td>\n","        <td><span style=\"color:blue;\">was little</span> <span style=\"color:red;\">bit</span> <span style=\"color:blue;\"> taller I</span></td>\n","    </tr>\n","    <tr>\n","        <td>5</td>\n","        <td><span style=\"color:blue;\">little bit</span> <span style=\"color:red;\">taller</span> <span style=\"color:blue;\"> I wish</span></td>\n","    </tr>\n","    <tr>\n","        <td>6</td>\n","        <td><span style=\"color:blue;\">bit taller</span> <span style=\"color:red;\">I</span> <span style=\"color:blue;\">wish I</span></td>\n","    </tr>\n","    <tr>\n","        <td>7</td>\n","        <td><span style=\"color:blue;\">taller I</span> <span style=\"color:red;\">wish</span> <span style=\"color:blue;\">I was</span></td>\n","    </tr>\n","    <tr>\n","        <td>8</td>\n","        <td><span style=\"color:blue;\">I wish</span> <span style=\"color:red;\">I</span> <span style=\"color:blue;\">was a</span></td>\n","    </tr>\n","    <tr>\n","        <td>9</td>\n","        <td><span style=\"color:blue;\">wish I</span> <span style=\"color:red;\">was</span> <span style=\"color:blue;\">a baller</span></td>\n","    </tr>\n","</table>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"16643c7a-2540-4daa-abc1-ca2bb76c9421"},"source":["You can slide over the sequence and create training data:\n"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"c6c25706-fbb9-4ccc-ad6b-35e5c7fada5e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738421617979,"user_tz":-300,"elapsed":448,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}},"outputId":"3b1f39f3-5075-40cf-b603-306fcc3c3a5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["(['i', 'w', 'h', 'I'], 's')\n"]}],"source":["CONTEXT_SIZE = 2  # Defines the number of words to consider as context on each side\n","\n","cobow_data = []  # List to store (context, target) word pairs\n","\n","# Ensure enough data exists for CBOW pairs\n","if len(flat_tokenized_data) > CONTEXT_SIZE:\n","    # Iterate through the tokenized toy data to create CBOW training pairs\n","    for i in range(CONTEXT_SIZE, len(flat_tokenized_data) - CONTEXT_SIZE):\n","        # Extract the context words: CONTEXT_SIZE words before and after the target word\n","        context = (\n","            [flat_tokenized_data[i - j - 1] for j in range(CONTEXT_SIZE)] +  # Words before target\n","            [flat_tokenized_data[i + j + 1] for j in range(CONTEXT_SIZE)]  # Words after target\n","        )\n","\n","        target = flat_tokenized_data[i]  # Define the target word\n","\n","        # Append the (context, target) pair to the dataset\n","        cobow_data.append((context, target))\n","\n","    # Print the second (context, target) pair if it exists\n","    if len(cobow_data) > 1:\n","        print(cobow_data[1])\n","    else:\n","        print(\"Not enough data for a second (context, target) pair.\")\n","else:\n","    print(\"Insufficient tokenized data to generate CBOW pairs.\")\n"]},{"cell_type":"markdown","metadata":{"id":"e866f301-c794-4213-8749-51d0b55ae663"},"source":["\n","You can print a sample, showcasing both the context words ['wish', 'i', 'was', 'little'] and the target word 'i':\n","<table border=\"1\">\n","    <tr>\n","        <th>Time Step</th>\n","        <th>Phrase</th>\n","    </tr>\n","    <tr>\n","        <td>1</td>\n","        <td><span style=\"color:blue;\">I wish</span> <span style=\"color:red;\">I</span> <span style=\"color:blue;\">was  little </span></td>\n","    </tr>\n","</table>\n"]},{"cell_type":"markdown","metadata":{"id":"e5cd73c6-3035-4793-be1a-e21a8d672955"},"source":["You can print the next sample, showcasing both the context ['i', 'wish', 'little', 'bit'] and the target words:'was'\n","<table border=\"1\">\n","    <tr>\n","        <th>Time Step</th>\n","        <th>Phrase</th>\n","    </tr>\n","    <tr>\n","        <td>2</td>\n","        <td><span style=\"color:blue;\">wish I</span> <span style=\"color:red;\">was</span> <span style=\"color:blue;\"> little bit</span></td>\n","    </tr>\n","</table>\n"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"7dbf70dc-a4d8-43f5-82eb-f5e45b7a292c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738421488091,"user_tz":-300,"elapsed":450,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}},"outputId":"af5e50a6-cdf9-4d3a-b96a-dc14201e69e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["(['s', 'i', 'I', 'w'], 'h')\n"]}],"source":["print(cobow_data[2])"]},{"cell_type":"markdown","metadata":{"id":"d4822594-9163-43c2-a739-2f1d2478c1e2"},"source":["You would want to find the emeddings that guide the model to predict the following probilaties. $P(w_t| w_{t-2},w_{t-1},w_{t+1},w_{t+2})$ is the probability of $w_t$, the target word, conditioned on the occurrence of context words $w_{t-2},w_{t-1},w_{t+1},w_{t+2}$.\n"]},{"cell_type":"markdown","metadata":{"id":"e1a88ff9-7118-4290-9da5-729db6735173"},"source":["<table border=\"1\">\n","    <thead>\n","        <tr>\n","            <th>\\( P(w_t| w_{t-2},w_{t-1},w_{t+1},w_{t+2}) \\)</th>\n","        </tr>\n","    </thead>\n","    <tbody>\n","        <tr>\n","            <td>\\( P(w_1 | w_{-1},w_0,w_2,w_3) = P(I | \\text{I wish, was little}) \\)</td>\n","        </tr>\n","        <tr>\n","            <td>\\( P(w_2 | w_0,w_1,w_3,w_4) = P(was | \\text{wish I, little bit}) \\)</td>\n","        </tr>\n","        <tr>\n","            <td>\\( P(w_3 | w_1,w_2,w_4,w_5) = P(little | \\text{I was, bit taller}) \\)</td>\n","        </tr>\n","        <tr>\n","            <td>\\( P(w_4 | w_2,w_3,w_5,w_6) = P(bit | \\text{was little, taller I}) \\)</td>\n","        </tr>\n","        <tr>\n","            <td>\\( P(w_5 | w_3,w_4,w_6,w_7) = P(taller | \\text{little bit, I wish}) \\)</td>\n","        </tr>\n","        <tr>\n","            <td>\\( P(w_6 | w_4,w_5,w_7,w_8) = P(I | \\text{bit taller, wish I}) \\)</td>\n","        </tr>\n","        <tr>\n","            <td>\\( P(w_7 | w_5,w_6,w_8,w_9) = P(wish | \\text{taller I, I was}) \\)</td>\n","        </tr>\n","    </tbody>\n","</table>\n"]},{"cell_type":"markdown","metadata":{"id":"8994f520-0db4-4dec-b1f8-4da236f53cfb"},"source":["The collate_batch function processes batches of data, converting context and target text data into numerical format using a vocabulary and arranging them for model training.\n"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"10a3fbbb-f170-467f-982b-f3b5e9e0a663","executionInfo":{"status":"ok","timestamp":1738422293499,"user_tz":-300,"elapsed":435,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}}},"outputs":[],"source":["def collate_batch(batch):\n","    target_list, context_list, offsets = [], [], [0]\n","    for _context, _target in batch:\n","\n","        target_list.append(vocab[_target])\n","        processed_context = torch.tensor(text_pipeline(_context), dtype=torch.int64)\n","        context_list.append(processed_context)\n","        offsets.append(processed_context.size(0))\n","    target_list = torch.tensor(target_list, dtype=torch.int64)\n","    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n","    context_list = torch.cat(context_list)\n","    return target_list.to(device), context_list.to(device), offsets.to(device)"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"925812f2-6d93-402b-93b9-1e8da069b84d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738422300179,"user_tz":-300,"elapsed":501,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}},"outputId":"1aa5f38d-9876-4482-8c83-ae248c9fe7b9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":53}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"markdown","metadata":{"id":"6c9b1a84-2200-4196-ae1d-5f3294cd99c0"},"source":["Selecting the first 10 samples from the `cobow_data` list and processing them using the `collate_batch` function. The outputs are the tokenized target words (`target_list`), the surrounding context words (`context_list`), and the respective offsets for each sample (`offsets`).\n"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"f59ac866-a04d-45d6-b0fe-12da1218f638","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738422308097,"user_tz":-300,"elapsed":417,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}},"outputId":"3711c85d-db49-436a-bd4b-7d7348cba4e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["target_list(Tokenized target words): tensor([ 4,  5,  7, 30, 17,  2,  5, 10,  4,  3], device='cuda:0') , context_list(Surrounding context words): tensor([17, 30,  5,  7,  4, 17,  7, 30,  5,  4, 30, 17,  7,  5, 17,  2, 30,  7,\n","         2,  5, 17, 30,  5, 10,  2, 17, 10,  4,  5,  2,  4,  3, 10,  5,  3,  3,\n","         4, 10,  3, 10], device='cuda:0') , offsets(Starting indexes of context words for each target): tensor([ 0,  4,  8, 12, 16, 20, 24, 28, 32, 36], device='cuda:0') \n"]}],"source":["target_list, context_list, offsets=collate_batch(cobow_data[0:10])\n","print(f\"target_list(Tokenized target words): {target_list} , context_list(Surrounding context words): {context_list} , offsets(Starting indexes of context words for each target): {offsets} \")\n"]},{"cell_type":"markdown","metadata":{"id":"87814df6-00ce-411e-a494-b1f8d76c803e"},"source":["Create a ```dataLoader``` object:\n"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"32df3d49-8dc2-4678-a621-230a35e88ca9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738422347529,"user_tz":-300,"elapsed":430,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}},"outputId":"4dd2232e-50a8-4f92-b652-9a46b4a57a83"},"outputs":[{"output_type":"stream","name":"stdout","text":["<torch.utils.data.dataloader.DataLoader object at 0x7eba8aff5a10>\n"]}],"source":["BATCH_SIZE = 64  # batch size for training\n","\n","dataloader_cbow = DataLoader(\n","    cobow_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n","print(dataloader_cbow)"]},{"cell_type":"markdown","metadata":{"id":"fd14c334-c0b6-4748-ab5f-dcc4b7c1bf75"},"source":["The CBOW model shown here starts with an EmbeddingBag layer, which takes a variable-length list of context word indices and produces an averaged embedding of size embed_dim. This embedding is then passed through a linear layer that reduces its dimension to ```embed_dim/2```. After applying a ReLU activation, the output is processed by another linear layer, transforming it to match the vocabulary size, thus allowing the model to predict the probability of any word from the vocabulary as the target word. The overall flow moves from contextual words' indices to predicting the central word in the Continuous Bag of Words approach.\n"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"d7fe84ef-d7fb-40bd-aace-0b6ac9477e7b","executionInfo":{"status":"ok","timestamp":1738422360027,"user_tz":-300,"elapsed":442,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}}},"outputs":[],"source":["class CBOW(nn.Module):\n","    # Initialize the CBOW model\n","    def __init__(self, vocab_size, embed_dim, num_class):\n","\n","        super(CBOW, self).__init__()\n","         # Define the embedding layer using nn.EmbeddingBag\n","        # It outputs the average of context words embeddings\n","        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n","        # Define the first linear layer with input size embed_dim and output size embed_dim//2\n","        self.linear1 = nn.Linear(embed_dim, embed_dim//2)\n","        # Define the fully connected layer with input size embed_dim//2 and output size vocab_size\n","        self.fc = nn.Linear(embed_dim//2, vocab_size)\n","\n","\n","        self.init_weights()\n","    # Initialize the weights of the model's parameters\n","    def init_weights(self):\n","        # Initialize the weights of the embedding layer\n","        initrange = 0.5\n","        self.embedding.weight.data.uniform_(-initrange, initrange)\n","        # Initialize the weights of the fully connected layer\n","        self.fc.weight.data.uniform_(-initrange, initrange)\n","        # Initialize the biases of the fully connected layer to zeros\n","        self.fc.bias.data.zero_()\n","\n","\n","    def forward(self, text, offsets):\n","        # Pass the input text and offsets through the embedding layer\n","        out = self.embedding(text, offsets)\n","        # Apply the ReLU activation function to the output of the first linear layer\n","        out = torch.relu(self.linear1(out))\n","        # Pass the output of the ReLU activation through the fully connected layer\n","        return self.fc(out)\n"]},{"cell_type":"markdown","metadata":{"id":"0590856e-938f-407e-9d1f-ffe0245bbc11"},"source":["Create an instance of the CBOW model:\n"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"462c54ba-eb63-4493-b1ee-273745239606","executionInfo":{"status":"ok","timestamp":1738422367368,"user_tz":-300,"elapsed":440,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}}},"outputs":[],"source":["vocab_size = len(vocab)\n","emsize = 24\n","model_cbow = CBOW(vocab_size, emsize, vocab_size).to(device)"]},{"cell_type":"markdown","metadata":{"id":"9474d68d-2b0e-4a41-ae9b-91607e6625c2"},"source":["Define the loss function, optimizer, and scheduler for training:\n"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"9fb811ce-f1db-4ce6-a2cd-acf838374451","executionInfo":{"status":"ok","timestamp":1738422377580,"user_tz":-300,"elapsed":4300,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}}},"outputs":[],"source":["\n","LR = 5  # learning rate\n","\n","# Define the CrossEntropyLoss criterion. It is commonly used for multi-class classification tasks.\n","# This criterion combines the softmax function and the negative log-likelihood loss.\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# Define the optimizer using stochastic gradient descent (SGD).\n","# It optimizes the parameters of the model_cbow, which are obtained by model_cbow.parameters().\n","# The learning rate (lr) determines the step size for parameter updates during optimization.\n","optimizer = torch.optim.SGD(model_cbow.parameters(), lr=LR)\n","\n","# Define a learning rate scheduler.\n","# The StepLR scheduler adjusts the learning rate during training.\n","# It multiplies the learning rate by gamma every step_size epochs (here, 1.0).\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n"]},{"cell_type":"markdown","metadata":{"id":"facaa495-c9fc-4c74-9885-9caf414ffba0"},"source":["Let's train the model:\n"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"e2eab1ef-5042-4c1b-ba2e-abae8e4123dd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738422442225,"user_tz":-300,"elapsed":57200,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}},"outputId":"ef52fee9-fb5a-4037-b5bb-c1783fe8ba94"},"outputs":[{"output_type":"stream","name":"stderr","text":["Training Progress: 100%|██████████| 400/400 [00:57<00:00,  7.01it/s]\n"]}],"source":["model_cbow, epoch_losses=train_model(model_cbow, dataloader_cbow, criterion, optimizer, num_epochs=400)"]},{"cell_type":"markdown","metadata":{"id":"03d8d872-83e6-4ccb-b08d-6211078bf689"},"source":["Now, you can plot the loss values over the course of training:\n"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"2b4305f4-a6e3-44ed-93d2-801704c02603","colab":{"base_uri":"https://localhost:8080/","height":467},"executionInfo":{"status":"ok","timestamp":1738422457098,"user_tz":-300,"elapsed":560,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}},"outputId":"55545aa9-017f-4102-d18c-1a1b961c2962"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 0, 'epochs')"]},"metadata":{},"execution_count":60},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["plt.plot(epoch_losses)\n","plt.xlabel(\"epochs\")\n"]},{"cell_type":"markdown","metadata":{"id":"e411f9ca-8a12-4280-802c-d3fbea0fb342"},"source":["The model's weights are the actual word embeddings. You can load them into a numpy array:\n"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"9b3119c5-3ad0-4c1b-9a9f-c70643f87147","executionInfo":{"status":"ok","timestamp":1738422482148,"user_tz":-300,"elapsed":418,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}}},"outputs":[],"source":["word_embeddings = model_cbow.embedding.weight.detach().cpu().numpy()"]},{"cell_type":"markdown","metadata":{"id":"9cb0b103-7a0e-43b9-b784-3319dd2bd6a8"},"source":["Now, check the embedded vector for a sample word. Notice the shape of this vector which is equal to the `emsize = 24` that you defined earlier.\n"]},{"cell_type":"code","source":["# from collections import Counter\n","# from itertools import chain\n","# import nltk\n","# import torch\n","# from torch.utils.data import DataLoader\n","# import torch.nn as nn\n","# import torch.optim as optim\n","\n","# nltk.download('punkt')  # Ensure NLTK tokenizer is available\n","# from nltk.tokenize import word_tokenize\n","\n","# tokenizer = word_tokenize  # Use NLTK's word tokenizer\n","\n","# # Step 2: Function to tokenize sentences\n","# def tokenize_data(sentences):\n","#     \"\"\"\n","#     Tokenizes each sentence in the given list of sentences.\n","\n","#     Args:\n","#         sentences (list): List of sentences to tokenize.\n","\n","#     Returns:\n","#         list: List of tokenized words from each sentence.\n","#     \"\"\"\n","#     return [tokenizer(sentence) for sentence in sentences]\n","\n","# # Tokenizing toy data (sample toy_data to test the pipeline)\n","# tokenized_toy_data = tokenize_data(toy_data)\n","\n","# # Flatten the tokenized data to create a single list of words\n","# flat_tokenized_data = list(chain(*tokenized_toy_data))\n","\n","# # Step 3: Build vocabulary from tokenized data with <unk> (unknown) token\n","# counter = Counter(flat_tokenized_data)  # Count word occurrences\n","# vocab = {word: idx for idx, (word, _) in enumerate(counter.most_common(), start=1)}\n","# vocab[\"<unk>\"] = 0  # Assign index 0 to unknown token\n","\n","# # Test a sample sentence\n","# sample_sentence = \"I wish I was a baller\"\n","# tokenized_sample = tokenizer(sample_sentence)\n","\n","# # Encode the tokenized words using the vocabulary\n","# encoded_sample = [vocab.get(token, vocab[\"<unk>\"]) for token in tokenized_sample]\n","\n","# # Print the encoded representation of the sample sentence\n","# print(\"Encoded sample:\", encoded_sample)\n","\n","# # Define a text pipeline for encoding\n","# def text_pipeline(tokens):\n","#     return [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]\n","\n","# # Check if 'baller' is in the vocabulary and print its word embedding\n","# word = 'baller'\n","\n","# # Ensure 'baller' exists in vocab\n","# if word in vocab:\n","#     word_index = vocab[word]  # getting the index of the word in the vocab\n","#     print(f\"Word index for '{word}': {word_index}\")\n","#     word_embeddings = model_cbow.embedding.weight.detach().cpu().numpy()\n","#     print(word_embeddings[word_index])\n","# else:\n","#     print(f\"'{word}' is not in the vocabulary. Checking <unk> index...\")\n","#     word_index = vocab[\"<unk>\"]\n","#     print(f\"Using <unk> token embedding: {word_index}\")\n","#     word_embeddings = model_cbow.embedding.weight.detach().cpu().numpy()\n","#     print(word_embeddings[word_index])  # Print embedding for <unk>\n"],"metadata":{"id":"tjyFKjl1F4l7","executionInfo":{"status":"ok","timestamp":1738423258634,"user_tz":-300,"elapsed":644,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","execution_count":77,"metadata":{"id":"be938158-30ba-4232-8cb3-96fb4a69b8b2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738423263282,"user_tz":-300,"elapsed":456,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}},"outputId":"eaef39a9-3710-485c-ccbe-be8d23b442db"},"outputs":[{"output_type":"stream","name":"stdout","text":["[-0.37268233  0.7730446   0.00286675  0.18596819 -0.08756901 -0.13963117\n"," -0.3128581   0.5306341   0.1781773   0.01526112 -0.09133023  0.21041386\n"," -0.01982056  0.33116063  0.3302575  -0.4613755   0.21107204  0.74245965\n"," -0.00459926 -0.49854013  0.25461784 -1.0076723  -0.01938024 -0.17694472]\n"]}],"source":["word = 'baller'\n","\n","# Check if the word exists in the vocab\n","if word in vocab:\n","    word_index = vocab[word]  # getting the index of the word in the vocab\n","    print(word_embeddings[word_index])\n","else:\n","    print(f\"'{word}' is not in the vocabulary.\")"]},{"cell_type":"markdown","metadata":{"id":"f95c3cab-a9fe-45b2-bf5d-76d37bcc94f5"},"source":["Now you can check if embeddings are representing the similarities among words. To do this, for the sake of visualization,you need to do dimension reduction on word embeddings to map the embedding space to a 2-d space. You can do this using TSNE in the plot function in the helper functions section.\n"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"4c54e478-65c6-4be1-a448-804d0cbf0631","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1738423269444,"user_tz":-300,"elapsed":1208,"user":{"displayName":"Waleed Usman","userId":"03064618890249256362"}},"outputId":"4082508e-284e-43f6-c14e-3dc076434725"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x1500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["plot_embeddings(word_embeddings,vocab=vocab)"]},{"cell_type":"markdown","metadata":{"id":"30bcb11f-f651-4aee-afe1-f13295a284f1"},"source":["Upon examining the t-SNE projections, it is evident that even with the inevitable information loss from dimensionality reduction and the limitations of a small dataset, words with similar meanings cluster together. For instance, words such as 'bright' and 'shadow' are in proximity near the point (-15, -15) on components 1 and 2. Likewise, 'dog', 'cat', and 'mouse' are grouped around the (5, 5) coordinate, and 'sailed' as well as 'wind' can be found close to the (5, -8) point.\"\n"]},{"cell_type":"markdown","metadata":{"id":"cef1e2ba-1606-449a-b7ad-35649131029c"},"source":["## Skip-gram model\n","\n","The Skip-gram model is one of the two main architectures used in word2vec, a popular technique for learning word embeddings. In the Skip-gram model, the goal is to predict the surrounding words (context) given a central word (target). The main idea behind this model is that words that appear in similar contexts tend to have similar meanings.  Consider this example:\n","\n","**I was little bit taller,**\n","\n","Assuming a context window size of 2, the words in red represent the context, while the word highlighted in blue signifies the target:\n","\n","**<span style=\"color:red;\"> I was</span> <span style=\"color:blue;\">little</span> <span style=\"color:red;\">bit taller, </span>**\n","\n","### Window the Skip-gram:\n","\n","Training the Skip-gram model using the actual context can be computationally expensive. This is because it involves predicting probabilities for each word in the vocabulary for each position in the context as opposed to CBOW that predicts the probabilities for each word in the vocabulary for the target word only. To mitigate this, several approximation techniques are employed.\n","\n","One common approximation technique is to break the full context into smaller parts and predict them one at a time. This not only simplifies the prediction task but also helps in better training as it provides multiple training examples from a single context-target pair.\n","\n","### Using the first row of the table as an example:\n","\n","\n","For the example above the target word is **\"little\"**. The full context for this target word is:\n","**I was bit taller**\n","\n","In the approximation, instead of using the full context to predict the target, you should break it down. There are four approximations in this example:\n","1. Approximation 1: **I**\n","2. Approximation 2: **was**\n","3. Approximation 3: **bit**\n","4. Approximation 4: **taller**\n","\n","For each approximation, the Skip-gram model would aim to predict the target word \"little\" using just that part of the context. This means, for the first approximation, the model will try to predict \"little\" using only the word \"I\". For the second approximation, it will try using only the word \"was,\" and so on.\n","\n","In conclusion, the Skip-gram model aims to understand word relationships by predicting the context from a given target word. Approximation techniques, like the one illustrated, help simplify the training process and make it more efficient.\n"]},{"cell_type":"markdown","metadata":{"id":"c17137cb-eb8c-4766-9cf9-160a543d9795"},"source":["<table border=\"1\">\n","    <tr>\n","        <th>Full Context with Target</th>\n","        <th>Target Word</th>\n","        <th>Original Target Context</th>\n","        <th>Approximation 1</th>\n","        <th>Approximation 2</th>\n","        <th>Approximation 3</th>\n","        <th>Approximation 4</th>\n","    </tr>\n","    <tr>\n","        <td><span style=\"color:red;\"> I was</span> <span style=\"color:blue;\">little</span> <span style=\"color:red;\">bit taller, </span></td>\n","        <td>little</td>\n","        <td> I was bit taller,</td>\n","        <td>I</td>\n","        <td>was</td>\n","        <td>bit</td>\n","        <td>taller,</td>\n","    </tr>\n","    <tr>\n","        <td><span style=\"color:red;\"> was little</span> <span style=\"color:blue;\">bit</span> <span style=\"color:red;\">taller, I </span></td>\n","        <td>bit</td>\n","        <td>was little taller, I</td>\n","        <td>was</td>\n","        <td>little</td>\n","        <td>taller,</td>\n","        <td>I</td>\n","    </tr>\n","    <tr>\n","        <td><span style=\"color:red;\">little bit</span> <span style=\"color:blue;\">taller,</span> <span style=\"color:red;\">I wish </span></td>\n","        <td>taller,</td>\n","        <td>little bit I wish</td>\n","        <td>little</td>\n","        <td>bit</td>\n","        <td>I</td>\n","        <td>wish</td>\n","    </tr>\n","    <tr>\n","        <td><span style=\"color:red;\"> bit taller,</span> <span style=\"color:blue;\">I</span> <span style=\"color:red;\">wish I </span></td>\n","        <td>I</td>\n","        <td>bit taller, wish I</td>\n","        <td>bit</td>\n","        <td>taller,</td>\n","        <td>wish</td>\n","        <td>I</td>\n","    </tr>\n","    <tr>\n","        <td><span style=\"color:red;\"> taller, I</span> <span style=\"color:blue;\">wish</span> <span style=\"color:red;\">I was </span></td>\n","        <td>wish</td>\n","        <td>taller, I I was</td>\n","        <td>taller,</td>\n","        <td>I</td>\n","        <td>I</td>\n","        <td>was</td>\n","    </tr>\n","    <!-- More rows can be added in a similar pattern for other words in the phrase. -->\n","</table>\n"]},{"cell_type":"markdown","metadata":{"id":"2728b3c0-3ba6-4575-ad1d-8507a6c10b64"},"source":["The goal is to optimize the conditional probabilities for obtaining embeddings. Optimize the conditional probabilities for obtaining high-quality word embeddings. The only difference between continuous bag of words is the structure of the conditional probabilities $P(w_{t+j}| w_{t})$  for your window size $j=-2,-1,..,1,2.$\n"]},{"cell_type":"markdown","metadata":{"id":"aa13053b-fcb2-4c19-8876-5ffc10e22e0f"},"source":["<table border=\"1\">\n","    <tr>\n","        <th>j</th>\n","        <th>Target Word t=3 </th>\n","        <th>Context Word</th>\n","        <th>Probability</th>\n","    </tr>\n","    <tr>\n","         <th>-2</th>\n","        <td>little</td>\n","        <td>I</td>\n","        <td> P(I | little) </td>\n","    </tr>\n","    <tr>\n","          <th>-1</th>\n","        <td>little</td>\n","        <td>was</td>\n","        <td> P(was | little)</td>\n","    </tr>\n","    <tr>\n","         <th>1</th>\n","        <td>little</td>\n","        <td>bit</td>\n","        <td>P(bit | little)</td>\n","    </tr>\n","    <tr>\n","         <th>2</th>\n","        <td>little</td>\n","        <td>taller,</td>\n","        <td>P(taller | little) </td>\n","    </tr>\n","    <!-- Repeat rows for each context word for each target word -->\n","</table>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"109f4985-f7e3-4fe3-9eff-d79e6f703f93"},"source":["\n","In contrast to the standard notation in conditional probability, where the dependent variable is typically represented as the target, the current terminology reverses this convention.\n"]},{"cell_type":"markdown","metadata":{"id":"b45e350b-d2f5-4232-a3b4-8fb21b9f8134"},"source":["\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/targetvsdepenet.gif\" alt=\"image\">\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"b5d19bd7-6a9b-4040-b355-e489b5b45186"},"source":["This code constructs a skip-gram dataset from a tokenized toy data, where for each word (target), it gathers the surrounding words within a specified window (context) defined by CONTEXT_SIZE.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6e7942f3-b3fa-4d9e-94d9-bff583c4f08f"},"outputs":[],"source":["# Define the window size for the context around the target word.\n","CONTEXT_SIZE = 2\n","\n","# Initialize an empty list to store the (target, context) pairs.\n","skip_data = []\n","\n","# Iterate over each word in the tokenized toy_data, while excluding the first\n","# and last few words determined by the CONTEXT_SIZE.\n","for i in range(CONTEXT_SIZE, len(tokenized_toy_data) - CONTEXT_SIZE):\n","\n","    # For a word at position i, the context comprises of words from the preceding CONTEXT_SIZE\n","    # as well as from the succeeding CONTEXT_SIZE. The context words are collected in a list.\n","    context = (\n","        [tokenized_toy_data[i - j - 1] for j in range(CONTEXT_SIZE)]  # Preceding words\n","        + [tokenized_toy_data[i + j + 1] for j in range(CONTEXT_SIZE)]  # Succeeding words\n","    )\n","\n","    # The word at the current position i is taken as the target.\n","    target = tokenized_toy_data[i]\n","\n","    # Append the (target, context) pair to the skip_data list.\n","    skip_data.append((target, context))\n"]},{"cell_type":"markdown","metadata":{"id":"cdb3131f-a79a-4434-98cb-01187e5ae964"},"source":["You can window the skipgram\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b1d45faa-1ca5-4762-b5a8-bfe3f23b3e63"},"outputs":[],"source":["skip_data_=[[(sample[0],word) for word in  sample[1]] for sample in skip_data]"]},{"cell_type":"markdown","metadata":{"id":"4261419a-9710-4f63-a6e3-af741490d62b"},"source":["You will have pairs of (target, context) words:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d2a79b6c-f876-47cd-94cb-e48bd71e3535"},"outputs":[],"source":["skip_data_flat= [item  for items in  skip_data_ for item in items]\n","skip_data_flat[8:28]"]},{"cell_type":"markdown","metadata":{"id":"7836d727-08fa-40d4-8e86-14b0258ddfcf"},"source":["Creating a collate function to numericalize (target, context) pairs:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fe389b23-10e3-4c5e-9709-487602b3676f"},"outputs":[],"source":["def collate_fn(batch):\n","    target_list, context_list = [], []\n","    for _context, _target in batch:\n","\n","        target_list.append(vocab[_target])\n","        context_list.append(vocab[_context])\n","\n","    target_list = torch.tensor(target_list, dtype=torch.int64)\n","    context_list = torch.tensor(context_list, dtype=torch.int64)\n","    return target_list.to(device), context_list.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d487787f-e38e-4de6-828f-46019c294e15"},"outputs":[],"source":["dataloader = DataLoader(skip_data_flat, batch_size=BATCH_SIZE, collate_fn=collate_fn)"]},{"cell_type":"markdown","metadata":{"id":"beb07664-f468-4342-b722-a773f8a00753"},"source":["Let's check a sample batch of target,context after collation:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7d42cc8a-c062-4717-9d04-cf5a27ea9136"},"outputs":[],"source":["next(iter(dataloader))"]},{"cell_type":"markdown","metadata":{"id":"cd4edb04-5e93-409a-8e20-6d9be9dd905c"},"source":["Here, you will define the Skip-gram network.\n","The embeddings layer is defined using nn.Embedding, which creates word embeddings for the given vocabulary size and embedding dimension.\n","The fc layer is a fully connected layer with input dimension embed_dim and output dimension vocab_size.\n","\n","In the forward method, the input text is passed through the embeddings layer to obtain the word embeddings. The output of the embeddings layer is then passed through the fc layer.\n","The ReLU activation function is applied to the output of the fc layer. The final output is returned.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f4e63341-471a-4038-b787-95192888e184"},"outputs":[],"source":["class SkipGram_Model(nn.Module):\n","\n","    def __init__(self, vocab_size, embed_dim):\n","        super(SkipGram_Model, self).__init__()\n","        # Define the embeddings layer\n","        self.embeddings = nn.Embedding(\n","            num_embeddings=vocab_size,\n","            embedding_dim=embed_dim\n","        )\n","\n","        # Define the fully connected layer\n","        self.fc = nn.Linear(in_features=embed_dim, out_features=vocab_size)\n","\n","    def forward(self, text):\n","        # Perform the forward pass\n","        # Pass the input text through the embeddings layer\n","        out = self.embeddings(text)\n","\n","        # Pass the output of the embeddings layer through the fully connected layer\n","        # Apply the ReLU activation function\n","        out = torch.relu(out)\n","        out = self.fc(out)\n","\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"1bbce147-7168-4462-afb1-8f987cc1dd2d"},"source":["Creating an instance of the model:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ac9ed71d-7763-4eb6-89b3-206b907059a0"},"outputs":[],"source":["emsize = 24\n","model_sg = SkipGram_Model(vocab_size, emsize).to(device)"]},{"cell_type":"markdown","metadata":{"id":"64cf556f-0052-400a-9d5b-3c8d4756aba9"},"source":["Now you are going to train the model on toy data:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f39303d1-f98b-4288-a6a0-3cc80529bce9"},"outputs":[],"source":["LR = 5  # learning rate\n","#BATCH_SIZE = 64  # batch size for training\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model_sg.parameters(), lr=LR)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1ce1242-4d0b-42d2-b13b-506b5f78e035"},"outputs":[],"source":["model_sg, epoch_losses=train_model(model_sg, dataloader, criterion, optimizer, num_epochs=400)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ead1c4c1-d33b-47cc-8c6e-b61182d4525d"},"outputs":[],"source":["plt.plot(epoch_losses)"]},{"cell_type":"markdown","metadata":{"id":"ca4047ba-9148-4d90-a716-069fd24a6069"},"source":["You can also plot the word embedding by reducing the dimensions using t-SNE:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f77db1bc-cef4-424b-a82c-5b5fe041dd2d"},"outputs":[],"source":["word_embeddings = model_sg.embeddings.weight.detach().cpu().numpy()\n","plot_embeddings(word_embeddings,vocab=vocab)"]},{"cell_type":"markdown","metadata":{"id":"b6e6459d-fb48-44bb-8157-25df89f3a57d"},"source":["\n","When selecting CBOW or Skip-Gram, the best approach often depends on the specifics of your task and data. If your dataset is small but you need to have a good representation of rarer words, Skip-gram might be the better choice. If the computational efficiency is more critical and the rare words are less of a concern, CBOW might be adequate. It's also worth noting that for very small datasets, the benefits of neural word embeddings might be limited, and simpler methods or leveraging pretrained embeddings might be more effective.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1e544b44-4575-454c-b814-6d7ce6b7b46a"},"source":["# Applying pretrained word embeddings (optional)\n","## Load Stanford GloVe model\n","\n","Transfer learning, particularly through the use of pretrained word embeddings, serves as a cornerstone in modern NLP. This approach leverages knowledge gleaned from one task, typically learned over massive datasets, and applies it to another, often more specialized task. The primary advantage of this is twofold: it bypasses the need for enormous computational resources to learn from scratch, and it injects a base layer of linguistic understanding into the model. By using embeddings that have already captured complex language patterns and associations, even models with limited exposure to domain-specific data can exhibit remarkably sophisticated behavior, making transfer learning a strategic shortcut to enhanced performance in NLP.\n"]},{"cell_type":"markdown","metadata":{"id":"44fe77d8-f3c4-4645-8729-57e6ef3592a4"},"source":["Let's take a look at the pretrained GloVe model from Stanford:\n"]},{"cell_type":"markdown","metadata":{"id":"aa124eca-ca59-45d8-9ee0-e17a1d76c023"},"source":["You can specify the model name and embedding dimension: GloVe(name='GloVe_model_name', dim=300)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9604dd2c-082b-4ce0-8773-11fab32d08da"},"outputs":[],"source":["# creating an instance of the 6B version of Glove() model\n","glove_vectors_6B = GloVe(name ='6B') # you can specify the model with the following format: GloVe(name='840B', dim=300)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bd318682-c5e5-4d46-8517-dd18d4093371"},"outputs":[],"source":["# creating another instance of a bigger Glove() model\n","#glove_vectors_840B = GloVe()"]},{"cell_type":"markdown","metadata":{"id":"35567636-9cc8-47a0-b829-c0860ccf5cda"},"source":["You must continue with the 6B model as it is lighter. You can load different pretrained GloVe models from torch() using ```torch.nn.Embedding.from_pretrained```.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8cee7cd8-6000-4c1d-bf99-1a479f1c4ac7"},"outputs":[],"source":["# load the glove model pretrained weights into a PyTorch embedding layer\n","embeddings_Glove6B = torch.nn.Embedding.from_pretrained(glove_vectors_6B.vectors,freeze=True)"]},{"cell_type":"markdown","metadata":{"id":"b868a5d3-ae6b-46f2-92c5-32afad537560"},"source":["Get ready to look into the embedding vectors of this large pretrained model for the words in the corpus:\n"]},{"cell_type":"markdown","metadata":{"id":"ba8e51d9-9ed0-43a2-b593-be9f9935ff44"},"source":["You can create an array that returns the index of each word in the GloVe model's vocabulary:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c80cf250-3931-42f2-9817-9dbdccae1672"},"outputs":[],"source":["word_to_index = glove_vectors_6B.stoi  # Vocabulary index mapping\n","word_to_index['team']"]},{"cell_type":"markdown","metadata":{"id":"6326b6c2-23fe-42e0-8316-5377e0f44e75"},"source":["You will get the embedded vector for a word:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2c71d12a-c1d8-4dcb-b99e-2a1f0ed40ad5"},"outputs":[],"source":["embeddings_Glove6B.weight[word_to_index['team']]"]},{"cell_type":"markdown","metadata":{"id":"4ec32c06-f3e3-42fc-9bbf-4c1651a8ed99"},"source":["Let's see how successful the Glove model is in capturing the similarities between words:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"be9d81e2-df06-486e-a94a-adefcd8a043d"},"outputs":[],"source":["# an array of example words\n","words = [\n","    \"taller\",\n","    \"short\",\n","    \"black\",\n","    \"white\",\n","    \"dress\",\n","    \"pants\",\n","    \"big\",\n","    \"small\",\n","    \"red\",\n","    \"blue\",\n","    \"smile\",\n","    \"frown\",\n","    \"race\",\n","    \"stroll\",\n","    \"tiny\",\n","    \"huge\",\n","    \"soft\",\n","    \"rough\",\n","    \"team\",\n","    \"individual\"\n","]\n"]},{"cell_type":"markdown","metadata":{"id":"24287699-99f6-4b5a-beed-ca8b0e2356de"},"source":["Create a dictionary of words and their embeddings\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9979c494-b32b-4a47-96a3-fab36c8aaa92"},"outputs":[],"source":["\n","embedding_dict_Glove6B = {}\n","for word in words:\n","    # Get the index of the word from the vocabulary to access its embedding\n","    embedding_vector = embeddings_Glove6B.weight[word_to_index[word]]\n","    if embedding_vector is not None:\n","        # Words not found in the embedding index will be skipped.\n","        # add the embedding vector of word to the embedding_dict_Glove6B\n","        embedding_dict_Glove6B[word] = embedding_vector\n"]},{"cell_type":"markdown","metadata":{"id":"8200b763-5eab-4d70-bb6c-afcd91dfa7df"},"source":["Now that you have loaded the pretrained embeddings for the sample words, let's check if the model can capture the similarity of words by finding the distance between words:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1350bcc6-2fa5-416a-8ef8-6140658c99a7"},"outputs":[],"source":["# Call the function to find similar words\n","target_word = \"small\"\n","top_k=2\n","similar_words = find_similar_words(target_word, embedding_dict_Glove6B, top_k)\n","\n","# Print the similar words\n","print(\"{} most similar words to {}:\".format(top_k,target_word) ,similar_words)"]},{"cell_type":"markdown","metadata":{"id":"e4309399-134b-4b13-9962-dfbafcb62510"},"source":["It can be seen the pretrained GloVe model does quite good job capturing the similarity of words.\n"]},{"cell_type":"markdown","metadata":{"id":"3f7c7561-0c23-44ad-9a1c-cdf6b60c66d4"},"source":["# Train a word2vec model from gensim\n","\n","Here's a simple hands-on exercise to train a word2vec model using `gensim` library.\n","In this example, you have a small corpus consisting of four sentences.\n","\n","### Prepare your corpus:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d381d354-923e-42dc-8155-2fbaadd3b2d0"},"outputs":[],"source":["sentences = [[\"I\", \"like\", \"to\", \"eat\", \"pizza\"],\n","             [\"Pizza\", \"is\", \"my\", \"favorite\", \"food\"],\n","             [\"I\", \"enjoy\", \"eating\", \"pasta\"]]\n","sentences = [[word.lower() for word in sentence] for sentence in sentences]\n"]},{"cell_type":"markdown","metadata":{"id":"ed2ce56f-376a-4694-9187-c0f0d67927ec"},"source":["The `size` parameter specifies the dimensionality of the word embeddings (in this case, 100). The `window` parameter determines the size of the context window. The `min_count` parameter sets the minimum frequency of a word to be included in the training process. Finally, the `workers` parameter controls the number of threads used for training.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c3a6a2f0-41f9-4f6a-b898-208525e5097d"},"outputs":[],"source":["from gensim.models import Word2Vec\n","\n","# Create an instance of Word2Vec model\n","w2v_model = Word2Vec(sentences, vector_size=100, window=3, min_count=1, workers=4)"]},{"cell_type":"markdown","metadata":{"id":"a89275e4-41c7-4c93-9ba7-c998d8c89a19"},"source":["Create vocab from sentences:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3531bce-a0aa-445f-b2aa-56d74ac76345"},"outputs":[],"source":["# Build vocab using the training data\n","w2v_model.build_vocab(sentences, progress_per=10000)"]},{"cell_type":"markdown","metadata":{"id":"1dfec3cb-8da5-4ced-ae1e-717fe3ef7a4e"},"source":["Train the model:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"55a2fcb3-8324-4c76-b892-547e19c7074c"},"outputs":[],"source":["# Train the model on your training data\n","w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"]},{"cell_type":"markdown","metadata":{"id":"b6be962e-6fb1-4bc6-9088-a9c0320d8ff5"},"source":["That's it! You've trained a word2vec model using the `gensim` library. You can now access the word embeddings using `model.wv` and explore various operations such as finding similar words, calculating word similarities, and more.\n"]},{"cell_type":"markdown","metadata":{"id":"0cc7cce8-0c3c-41c7-ad30-4e5eba394f2c"},"source":["Use the trained model to find similar words to \"pizza\" and calculate the similarity between \"pizza\" and \"pasta\".\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d46fc12e-4e24-41af-b78a-0c07423f8c12"},"outputs":[],"source":["# Finding similar words\n","similar_words = w2v_model.wv.most_similar(\"pizza\")\n","print(\"Similar words to 'pizza':\", similar_words)\n","\n","# Calculating word similarity\n","similarity = w2v_model.wv.similarity(\"pizza\", \"pasta\")\n","print(\"Similarity between 'pizza' and 'pasta':\", similarity)"]},{"cell_type":"markdown","metadata":{"id":"e8e582d0-ff2d-4c3e-aa44-34e8f4decd9b"},"source":["The word embeddings obtained from the model would be more meaningful and informative with larger and more diverse training data.\n"]},{"cell_type":"markdown","metadata":{"id":"49b6dab4-d77e-4674-8d2a-f995d709163a"},"source":["Use the trained model to create a PyTorch embedding layer (just like what you did with the pretrained GloVe model) and use it in any task as an embedding layer.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7131bfab-e394-42c0-aeca-42f073350c0a"},"outputs":[],"source":["# Extract word vectors and create word-to-index mapping\n","word_vectors = w2v_model.wv\n","# a dictionary to map words to their index in vocab\n","word_to_index = {word: index for index, word in enumerate(word_vectors.index_to_key)}\n","\n","# Create an instance of nn.Embedding and load it with the trained vectors\n","embedding_dim = w2v_model.vector_size\n","embedding = torch.nn.Embedding(len(word_vectors.index_to_key), embedding_dim)\n","embedding.weight.data.copy_(torch.from_numpy(word_vectors.vectors))\n","\n","# Example usage: get the embedding for a word\n","word = \"pizza\"\n","word_index = word_to_index[word]\n","word_embedding = embedding(torch.LongTensor([word_index]))\n","print(f\"Word: {word}, Embedding: {word_embedding.detach().numpy()}\")"]},{"cell_type":"markdown","metadata":{"id":"6c717ef1-d0c7-4151-94d3-ee6c36f30272"},"source":["# Text classification using pretrained word embeddings\n","\n","You are ready to use the embeddings in a task, then. Let's use the pretrained embeddings to classify text data into topics:\n"]},{"cell_type":"markdown","metadata":{"id":"7f4ee06c-a371-419a-aaf4-4696d33e946a"},"source":["First, you must build vocab from the pretrained GloVe:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"539e6172-1d00-4b64-96a0-b99c008d3e70"},"outputs":[],"source":["from torchtext.vocab import GloVe,vocab\n","# Build vocab from glove_vectors\n","# vocab(ordered_dict: Dict, min_freq: int = 1, specials: Optional[List[str]] = None)\n","vocab = vocab(glove_vectors_6B.stoi, 0,specials=('<unk>', '<pad>'))\n","vocab.set_default_index(vocab[\"<unk>\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c38cb532-51e2-4b2e-a56b-9936d982b7a5"},"outputs":[],"source":["vocab([\"<unk>\",\"Hello\",\"hello\"])"]},{"cell_type":"markdown","metadata":{"id":"fb059551-0268-44a0-85bd-69eb29be275d"},"source":["Next, you need to tokenize text. For this you can use pretrained tokenizers from torch:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f31fd8a5-4d1d-4286-b431-5d7cc3d8bd18"},"outputs":[],"source":["# Define tokenizer\n","\n","tokenizer = get_tokenizer(\"basic_english\")\n","# Define functions to process text and labels"]},{"cell_type":"markdown","metadata":{"id":"155fa10a-5506-403d-897a-60e2cae1f7ea"},"source":["Create splits from AG_NEWS() dataset for training, validation and test:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bee94b3f-ea27-4ef9-9586-ec3b4266123c"},"outputs":[],"source":["# Split the dataset into training and testing iterators.\n","train_iter, test_iter = AG_NEWS()\n","\n","# Convert the training and testing iterators to map-style datasets.\n","train_dataset = to_map_style_dataset(train_iter)\n","test_dataset = to_map_style_dataset(test_iter)\n","\n","# Determine the number of samples to be used for training and validation (5% for validation).\n","num_train = int(len(train_dataset) * 0.85)\n","\n","# Randomly split the training dat aset into training and validation datasets using `random_split`.\n","# The training dataset will contain 95% of the samples, and the validation dataset will contain the remaining 5%.\n","split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])"]},{"cell_type":"markdown","metadata":{"id":"8e409e21-385d-4e30-b2b2-873b3ed63b59"},"source":["Define the class labels:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"21dbe559-16a2-44f6-8954-31b56c05eeff"},"outputs":[],"source":["# define class labels\n","ag_news_label = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tec\"}\n","'''ag_news_label[y]'''\n","num_class = len(set([label for (label, text) in train_iter ]))"]},{"cell_type":"markdown","metadata":{"id":"10da74a3-d54c-4318-ac34-11ccea447154"},"source":["Collate data in batches:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b48aacfd-cc0c-49ed-95f1-fbbc2c5fd9fe"},"outputs":[],"source":["def text_pipeline(x):\n","    x=x.lower()# you need this as your vocab is in lower case\n","    return vocab(tokenizer(x))\n","\n","def label_pipeline(x):\n","    return int(x) - 1\n","\n","# create label, text and offset for each batch of data\n","# text is the concatenated text for all text data in the batch\n","# you need to have the offsets(the end of text index) for later when you separate texts and predict their label\n","def collate_batch(batch):\n","    label_list, text_list, offsets = [], [], [0]\n","    for _label, _text in batch:\n","        label_list.append(label_pipeline(_label))\n","        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n","        text_list.append(processed_text)\n","        offsets.append(processed_text.size(0))\n","\n","    label_list = torch.tensor(label_list, dtype=torch.int64)\n","    offsets = torch.tensor(offsets).cumsum(dim=0)\n","    text_list = torch.cat(text_list)\n","    return label_list.to(device), text_list.to(device), offsets.to(device)\n"]},{"cell_type":"markdown","metadata":{"id":"f34f460b-dcc9-4c2a-904f-8471aada9b40"},"source":["Create data loaders for train, validation and test splits:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6799bcdf-5f2b-4bd9-b3ea-3b5ec35ae02d"},"outputs":[],"source":["BATCH_SIZE = 64\n","\n","train_dataloader = DataLoader(\n","    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",")\n","valid_dataloader = DataLoader(\n","    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",")\n","test_dataloader = DataLoader(\n","    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"384f75db-46a9-48c7-89eb-429713739268"},"outputs":[],"source":["label, text, offsets=next(iter(train_dataloader ))\n","print(label, text, offsets)\n","label.shape, text.shape, offsets.shape"]},{"cell_type":"markdown","metadata":{"id":"7c0a2cfd-f4d7-476f-9b15-7f98ce61aed2"},"source":["Create the classifier model:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"99e6945c-0623-44e5-9050-a527562edb53"},"outputs":[],"source":["class TextClassificationModel(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, num_class):\n","        super(TextClassificationModel, self).__init__()\n","        self.embedding = torch.nn.Embedding.from_pretrained(glove_vectors_6B.vectors,freeze=True)\n","        self.fc = nn.Linear(embed_dim, num_class)\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        initrange = 0.5\n","        self.embedding.weight.data.uniform_(-initrange, initrange)\n","        self.fc.weight.data.uniform_(-initrange, initrange)\n","        self.fc.bias.data.zero_()\n","\n","    def forward(self, text,offsets):\n","        embedded = self.embedding(text)\n","        # you get the average of word embeddings in the text\n","        means = []\n","        for i in range(1,len(offsets)):\n","            #this is like eme\n","          text_tmp = embedded[offsets[i-1]:offsets[i]]\n","          means.append(text_tmp.mean(0))\n","\n","        return self.fc(torch.stack(means))"]},{"cell_type":"markdown","metadata":{"id":"ba31cfad-6364-49b7-91c3-0ed02676e49c"},"source":["Define an evaluate function to calculate the accuracy of model:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d822b01f-9cb6-4d22-a363-33717afaa57a"},"outputs":[],"source":["def evaluate(dataloader):\n","    model.eval()\n","    total_acc, total_count= 0, 0\n","\n","    with torch.no_grad():\n","        for idx, (label, text, offsets) in enumerate(dataloader):\n","            predicted_label = model(text,offsets)\n","\n","            total_acc += (predicted_label.argmax(1) == label).sum().item()\n","            total_count += label.size(0)\n","    return total_acc / total_count"]},{"cell_type":"markdown","metadata":{"id":"562a99ac-aae4-4c06-ab6b-1c2755b4302b"},"source":["Create an instance of the model and check its prediction power before training:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c74f8046-9997-438c-9f09-5ced30a39862"},"outputs":[],"source":["# Define hyperparameters\n","vocab_size=len(vocab)\n","embedding_dim = 300\n","# Initialize the model\n","model = TextClassificationModel(vocab_size, embedding_dim, num_class).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b0be682c-03a0-4c7b-b064-861e5f9205ca"},"outputs":[],"source":["evaluate(test_dataloader)"]},{"cell_type":"markdown","metadata":{"id":"835b8fc2-696d-4872-8a7a-28437127248a"},"source":["Not good! Let's train the model:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f88369c7-9113-4204-b81c-6a4b79fa9d40"},"outputs":[],"source":["def train_TextClassification(model,dataloader,criterion,optimizer,epochs=10):\n","\n","    cum_loss_list=[]\n","    acc_epoch=[]\n","    acc_old=0\n","\n","    for epoch in tqdm(range(1, EPOCHS + 1)):\n","        model.train()\n","        cum_loss=0\n","        for idx, (label, text, offsets) in enumerate(train_dataloader):\n","            means = []\n","            optimizer.zero_grad()\n","\n","\n","            predicted_label = model(text, offsets)\n","\n","            loss = criterion(predicted_label, label)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n","            optimizer.step()\n","            cum_loss+=loss.item()\n","\n","        cum_loss_list.append(cum_loss/len(train_dataloader))\n","        accu_val = evaluate(valid_dataloader)\n","        acc_epoch.append(accu_val)\n","\n","        if accu_val > acc_old:\n","          acc_old= accu_val\n","          torch.save(model.state_dict(), 'my_model.pth')\n","\n","    return model,cum_loss_list,acc_epoch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5aeb1a1-5baf-4206-b14e-e7585a09e802"},"outputs":[],"source":["# Define hyperparameters\n","LR=0.1\n","EPOCHS = 10\n","\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n","\n","model,cum_loss_list,acc_epoch  = train_TextClassification(model,train_dataloader,criterion,optimizer,EPOCHS)"]},{"cell_type":"markdown","metadata":{"id":"fed719b2-858f-4e81-acee-d6c96037b965"},"source":["Let's plot the loss and accuracy for the trained model:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1589448d-0d05-4784-aadb-8d9ff819d930"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","def plot(COST,ACC):\n","    fig, ax1 = plt.subplots()\n","    color = 'tab:red'\n","    ax1.plot(COST, color=color)\n","    ax1.set_xlabel('epoch', color=color)\n","    ax1.set_ylabel('total loss', color=color)\n","    ax1.tick_params(axis='y', color=color)\n","\n","    ax2 = ax1.twinx()\n","    color = 'tab:blue'\n","    ax2.set_ylabel('accuracy', color=color)  # you already handled the x-label with ax1\n","    ax2.plot(ACC, color=color)\n","    ax2.tick_params(axis='y', color=color)\n","    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9f8b63e0-b6f1-460b-b63e-e616d1e52040"},"outputs":[],"source":["plot(cum_loss_list,acc_epoch)"]},{"cell_type":"markdown","metadata":{"id":"b47effd6-fc93-4b4b-ba27-e64293479579"},"source":["Finally, evaluate the model on test data:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0214e22a-712d-416a-a625-119638bb9def"},"outputs":[],"source":["evaluate(test_dataloader)"]},{"cell_type":"markdown","metadata":{"id":"728ef01a-4d1f-4d1b-a4e6-c9172d053ceb"},"source":["Great job! You've acquired the skills to create and train embedding models, as well as utilize large pretrained models for practical applications. This knowledge opens up a world of possibilities where you can leverage the power of embeddings to improve various natural language processing tasks. Keep up the excellent work!\n"]},{"cell_type":"markdown","metadata":{"id":"e6948223-44b3-40eb-814b-69e04fff6ff4"},"source":["## Authors\n"]},{"cell_type":"markdown","metadata":{"id":"80f7c1f8-d8ad-4254-938f-f4967a7866da"},"source":["Fateme Akbari\n"]},{"cell_type":"markdown","metadata":{"id":"7a9a7a2a-4d25-4ae5-a1f4-ec5cd5797d6b"},"source":["```{## Change Log}\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"74a2edd5-dd8e-4759-b911-849b8c555b13"},"source":["```{|Date (YYYY-MM-DD)|Version|Changed By|Change Description||-|-|-|-||2023-10-16|0.1|Fateme|Create Lab Template|}\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"656805e6-7806-412a-aa8b-f5e02fc5b70d"},"source":["© Copyright IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"prev_pub_hash":"d8b55d962b308a81277ef91e9a81d5e951c13e7d48f1d3bf55c8cd47d33c8370","colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}