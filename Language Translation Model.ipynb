{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPrkp10uD/X5gqzwrVnHNtN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Sequence to Sequence Model for Language Translation (English to French)**"],"metadata":{"id":"vWG02jmWhzsb"}},{"cell_type":"markdown","source":["## Importing Libraries and Loading Data"],"metadata":{"id":"cDYymO7Rhwrz"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import spacy\n","from collections import Counter\n","import pickle\n","import os\n","import tarfile\n","import requests"],"metadata":{"id":"Bo8U78w8VUMg","executionInfo":{"status":"ok","timestamp":1738761340218,"user_tz":-300,"elapsed":8494,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!python -m spacy download de_core_news_sm\n","!python -m spacy download en_core_web_sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2zGEsmLjWPN4","executionInfo":{"status":"ok","timestamp":1738761378584,"user_tz":-300,"elapsed":20122,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}},"outputId":"6549408d-e820-4cd5-eaeb-552b1923cd0d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting de-core-news-sm==3.7.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.15.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.12.14)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n","Installing collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-3.7.0\n","\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('de_core_news_sm')\n","\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n","Collecting en-core-web-sm==3.7.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.12.14)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n","\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["# Download and Load SpaCy Tokenizers\n","spacy_de = spacy.load('de_core_news_sm')\n","spacy_en = spacy.load('en_core_web_sm')"],"metadata":{"id":"IrS_5oqIVkIq","executionInfo":{"status":"ok","timestamp":1738761384515,"user_tz":-300,"elapsed":2807,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#URLs for dataset\n","TRAIN_URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/training.tar.gz\"\n","VALID_URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/validation.tar.gz\""],"metadata":{"id":"L88I1bpkV4mc","executionInfo":{"status":"ok","timestamp":1738761389353,"user_tz":-300,"elapsed":579,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Special tokens\n","PAD_IDX,BOS_IDX,EOS_IDX,UNK_IDX=0,1,2,3\n","special_tokens=['<pad>', '<bos>', '<eos>', '<unk>']"],"metadata":{"id":"GSSCvrOVWiHu","executionInfo":{"status":"ok","timestamp":1738761393168,"user_tz":-300,"elapsed":985,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#Tokenize Functions\n","def tokenize_de(text):\n","  return [tok.text for tok in spacy_de.tokenizer(text)]\n","\n","def tokenize_en(text):\n","  return [tok.text for tok in spacy_de.tokenizer(text)]"],"metadata":{"id":"DIHRZaElW5_J","executionInfo":{"status":"ok","timestamp":1738761393713,"user_tz":-300,"elapsed":2,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#Function to download and extract data\n","def download_and_extract(url,extract_path):\n","  filename=url.split('/')[-1]\n","  file_path=os.path.join(extract_path, filename)\n","\n","  if not os.path.exists(extract_path):\n","    os.makedirs(extract_path)\n","\n","  if not os.path.exists(file_path):\n","    print(f\"Downloading {filename}...\")\n","    response=requests.get(url,stream=True)\n","    with open(file_path,'wb') as f:\n","      for chunk in response.iter_content(chunk_size=1024):\n","        if chunk:\n","          f.write(chunk)\n","\n","    print(f\"Downloaded {filename}\")\n","\n","\n","  #Ectract the tar.gz file\n","  with tarfile.open(file_path, 'r:gz') as tar:\n","    tar.extractall(path=extract_path)\n","    print(f\"Extracted {filename}\")\n"],"metadata":{"id":"FQxjVm7qXTwu","executionInfo":{"status":"ok","timestamp":1738761396394,"user_tz":-300,"elapsed":6,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#Function to crate Vocabulary\n","def build_vocab(sentences,tokenizer):\n","  counter=Counter()\n","  for sentence in sentences:\n","    counter.update(tokenizer(sentence))\n","  vocab={word: i+4 for i ,(word,_) in enumerate(counter.most_common())} # Offset for stepcial tokens\n","  for i, token in enumerate(special_tokens):\n","    vocab[token]=i # Assign special tokens\n","  return vocab"],"metadata":{"id":"FSfJvxDmDEEg","executionInfo":{"status":"ok","timestamp":1738761401959,"user_tz":-300,"elapsed":1080,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#Custom Dataset class\n","class TranslationDataset(Dataset):\n","  def __init__(self,src_sentences,tgt_sentences,src_vocab,tgt_vocab):\n","    self.src_sentences=src_sentences\n","    self.tgt_sentences=tgt_sentences\n","    self.src_vocab=src_vocab\n","    self.tgt_vocab=tgt_vocab\n","\n","  def __len__(self):\n","    return len(self.src_sentences)\n","\n","  def __getitem__(self,idx):\n","    src=[self.src_vocab.get(token,UNK_IDX) for token in tokenize_de(self.src_sentences[idx])]\n","    tgt=[self.tgt_vocab.get(token,UNK_IDX) for token in tokenize_en(self.tgt_sentences[idx])]\n","    return torch.tensor([BOS_IDX] + src + [EOS_IDX]),torch.tensor([BOS_IDX]+ tgt + [EOS_IDX])\n",""],"metadata":{"id":"U4peqJ65DwTn","executionInfo":{"status":"ok","timestamp":1738761402762,"user_tz":-300,"elapsed":9,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Function to load dataset\n","def load_data(data_dir):\n","  src_sentences,tgt_sentences=[],[]\n","\n","  train_src_path=os.path.join(data_dir,\"train.de\")\n","  train_tgt_path=os.path.join(data_dir,\"train.en\")\n","\n","  with open(train_src_path, 'r', encoding='utf-8') as src_file, open(train_tgt_path, 'r', encoding='utf-8') as tgt_file:\n","    for src_line,tgt_line in zip(src_file, tgt_file):\n","      src_sentences.append(src_line.strip())\n","      tgt_sentences.append(tgt_line.strip())\n","\n","\n","  src_vocab=build_vocab(src_sentences,tokenize_de)\n","  tgt_vocab=build_vocab(tgt_sentences, tokenize_en)\n","  dataset=TranslationDataset(src_sentences,tgt_sentences,src_vocab, tgt_vocab)\n","  return dataset,src_vocab,tgt_vocab"],"metadata":{"id":"FB7hrpcyFccM","executionInfo":{"status":"ok","timestamp":1738764306979,"user_tz":-300,"elapsed":549,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["#Collate function for padding\n","def collate_fn(batch):\n","  src_batch,tgt_batch=zip(*batch)\n","  src_batch=torch.nn.utils.rnn.pad_sequence(src_batch,padding_value=PAD_IDX,batch_first=True)\n","  tgt_batch=torch.nn.utils.rnn.pad_sequence(tgt_batch,padding_value=PAD_IDX,batch_first=True)\n","\n","  return src_batch,tgt_batch"],"metadata":{"id":"7hedCtU1IKo9","executionInfo":{"status":"ok","timestamp":1738761410755,"user_tz":-300,"elapsed":1077,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#Function to get DataLoaders\n","def get_dataloaders(batch_size=16,data_dir=\"data\"):\n","  download_and_extract(TRAIN_URL,data_dir)\n","  dataset,src_vocab,tgt_vocab=load_data(data_dir)\n","  dataloader=DataLoader(dataset,batch_size=batch_size,collate_fn=collate_fn,shuffle=True)\n","  return dataloader,src_vocab,tgt_vocab"],"metadata":{"id":"JbjnGOjZI9uy","executionInfo":{"status":"ok","timestamp":1738761412546,"user_tz":-300,"elapsed":5,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Building Seq2Seq Model"],"metadata":{"id":"hkRKZOp9QbNi"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","\n","# Encoder\n","class Encoder(nn.Module):\n","  def __init__(self,input_dim,emb_dim,hidden_dim,num_layers,dropout):\n","    super(Encoder,self).__init__()\n","    self.embedding=nn.Embedding(input_dim,emb_dim)\n","    self.rnn=nn.LSTM(emb_dim,hidden_dim,num_layers,dropout=dropout,batch_first=True)\n","    self.dropout=nn.Dropout(dropout)\n","\n","  def forward(self,src):\n","    embedded=self.dropout(self.embedding(src))\n","    output,(hidden,cell)=self.rnn(embedded)\n","    return hidden,cell\n"],"metadata":{"id":"yM88ixrEJt_O","executionInfo":{"status":"ok","timestamp":1738765865839,"user_tz":-300,"elapsed":1068,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# Decoder\n","class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hidden_dim, num_layers, dropout):\n","        super(Decoder, self).__init__()\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n","        self.fc_out = nn.Linear(hidden_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, tgt, hidden, cell):\n","        tgt = tgt.unsqueeze(1)  # Add sequence dimension\n","        embedded = self.dropout(self.embedding(tgt))\n","        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n","        prediction = self.fc_out(output.squeeze(1))\n","        return prediction, hidden, cell"],"metadata":{"id":"bG0NqRWZSBpC","executionInfo":{"status":"ok","timestamp":1738765868684,"user_tz":-300,"elapsed":5,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n","        batch_size, tgt_len = tgt.shape\n","        tgt_vocab_size = self.decoder.fc_out.out_features  # Get vocab size\n","\n","        # Store outputs\n","        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n","\n","        # Encode source sequence\n","        hidden, cell = self.encoder(src)\n","\n","        # First decoder input is <bos>\n","        input = tgt[:, 0].to(self.device)  # ‚úÖ Move to device\n","\n","        for t in range(1, tgt_len):\n","            output, hidden, cell = self.decoder(input, hidden, cell)\n","            outputs[:, t, :] = output  # ‚úÖ Store correctly\n","\n","            top1 = output.argmax(1).to(self.device)  # ‚úÖ Move to device\n","\n","            # Teacher forcing\n","            input = tgt[:, t].to(self.device) if torch.rand(1).item() < teacher_forcing_ratio else top1\n","\n","        return outputs\n"],"metadata":{"id":"jfJJMIu-UAI1","executionInfo":{"status":"ok","timestamp":1738765870814,"user_tz":-300,"elapsed":4,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["# Training\n","def train(model, dataloader, optimizer, criterion, device):\n","    model.train()\n","    epoch_loss = 0\n","\n","    for src, tgt in dataloader:\n","        src, tgt = src.to(device), tgt.to(device)  # Move tensors to device\n","        optimizer.zero_grad()\n","\n","        output = model(src, tgt)\n","        output_dim = output.shape[-1]\n","\n","        output = output[:, 1:].reshape(-1, output_dim)  # Flatten for loss function\n","        tgt = tgt[:, 1:].reshape(-1)  # Flatten targets\n","\n","        loss = criterion(output, tgt)\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(dataloader)\n"],"metadata":{"id":"Rz4g5-N2W8F7","executionInfo":{"status":"ok","timestamp":1738765874648,"user_tz":-300,"elapsed":605,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["# Evaluation\n","def evaluate(model, dataloader, criterion, device):\n","    model.eval()\n","    epoch_loss = 0\n","\n","    with torch.no_grad():\n","        for src, tgt in dataloader:\n","            src, tgt = src.to(device), tgt.to(device)  # Move to device\n","\n","            output = model(src, tgt, 0)  # No teacher forcing during evaluation\n","            output_dim = output.shape[-1]\n","\n","            output = output[:, 1:].reshape(-1, output_dim)\n","            tgt = tgt[:, 1:].reshape(-1)\n","\n","            loss = criterion(output, tgt)\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(dataloader)\n"],"metadata":{"id":"wIT6XpvYYHhV","executionInfo":{"status":"ok","timestamp":1738765878023,"user_tz":-300,"elapsed":1067,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# Hyperparameters and Training setup\n","device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","batch_size=16\n","embedding_dim=256\n","hidden_dim=512\n","num_layers=2\n","dropout=0.5\n","num_epochs=10"],"metadata":{"id":"5Ot4plhfZpyG","executionInfo":{"status":"ok","timestamp":1738766191496,"user_tz":-300,"elapsed":663,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["# Load Dataloader, Vocabulary\n","dataloader, src_vocab,tgt_vocab=get_dataloaders(batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FmzpDVBcaiPw","executionInfo":{"status":"ok","timestamp":1738766194984,"user_tz":-300,"elapsed":1374,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}},"outputId":"e22bbeec-cfe0-42f5-c9eb-c33fa57aa1ed"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted training.tar.gz\n"]}]},{"cell_type":"code","source":["# Model Setup\n","input_dim=len(src_vocab)\n","output_dim=len(tgt_vocab)\n","\n","encoder=Encoder(input_dim,embedding_dim,hidden_dim,num_layers,dropout).to(device)\n","decoder=Decoder(output_dim,embedding_dim,hidden_dim,num_layers,dropout).to(device)\n","model=Seq2Seq(encoder,decoder,device).to(device)\n","\n","optimizer=optim.Adam(model.parameters(), lr=0.001)\n","criterion=nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n"],"metadata":{"id":"OLqncGalasxV","executionInfo":{"status":"ok","timestamp":1738766195589,"user_tz":-300,"elapsed":14,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = Seq2Seq(encoder, decoder, device).to(device)  # ‚úÖ Move model to device"],"metadata":{"id":"mlCT_BV4hhwG","executionInfo":{"status":"ok","timestamp":1738766199800,"user_tz":-300,"elapsed":1025,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["# Training Loop\n","for epoch in range(num_epochs):\n","  train_loss=train(model,dataloader,optimizer,criterion,device)\n","  val_loss=evaluate(model,dataloader,criterion,device)\n","\n","  print(f\"Epoch {epoch+1}: Train Loss= {train_loss :.4f} , Val Loss= {val_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JVfRAwt9crWZ","executionInfo":{"status":"ok","timestamp":1738767733413,"user_tz":-300,"elapsed":1530939,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}},"outputId":"06497e44-76cd-4894-bf03-e2e3aba8a135"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Train Loss= 4.7183 , Val Loss= 4.6844\n","Epoch 2: Train Loss= 4.0945 , Val Loss= 4.3995\n","Epoch 3: Train Loss= 3.8295 , Val Loss= 4.2137\n","Epoch 4: Train Loss= 3.6247 , Val Loss= 4.0378\n","Epoch 5: Train Loss= 3.4623 , Val Loss= 3.9139\n","Epoch 6: Train Loss= 3.3218 , Val Loss= 3.8320\n","Epoch 7: Train Loss= 3.1888 , Val Loss= 3.6684\n","Epoch 8: Train Loss= 3.0677 , Val Loss= 3.5929\n","Epoch 9: Train Loss= 2.9642 , Val Loss= 3.5035\n","Epoch 10: Train Loss= 2.8688 , Val Loss= 3.3899\n"]}]},{"cell_type":"code","source":["#mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-_FSoiydsYB","executionInfo":{"status":"ok","timestamp":1738768044878,"user_tz":-300,"elapsed":19739,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}},"outputId":"375e05a1-fc21-4d45-f3a1-daf203724b81"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["drive_path=\"/content/drive/MyDrive/NLP Learning Labs/seq2seq_model.pth\"\n","\n","# Save model function\n","def save_model(model, optimizer, epoch, loss, path=drive_path):\n","    checkpoint = {\n","        \"epoch\": epoch,\n","        \"model_state_dict\": model.state_dict(),\n","        \"optimizer_state_dict\": optimizer.state_dict(),\n","        \"loss\": loss\n","    }\n","    torch.save(checkpoint, path)\n","    print(f\"‚úÖ Model saved at {path}\")"],"metadata":{"id":"1Q8EQTX8qB4k","executionInfo":{"status":"ok","timestamp":1738768184811,"user_tz":-300,"elapsed":532,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["save_model(model, optimizer, epoch, val_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9j3tbFnqXdW","executionInfo":{"status":"ok","timestamp":1738768222547,"user_tz":-300,"elapsed":1730,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}},"outputId":"ad1e72c5-181f-447c-b862-6a2e59a9a25c"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Model saved at /content/drive/MyDrive/NLP Learning Labs/seq2seq_model.pth\n"]}]},{"cell_type":"markdown","source":["## Load the Model from Drive"],"metadata":{"id":"yxJ8o4rpqbz2"}},{"cell_type":"code","source":["def load_model(model,optimizer,path,drive_path):\n","  if os.path.exists(path):\n","    checkpoint=torch.load(path,map_location=device)\n","    model.load_state_dict(checkpoint[\"model_state_dict\"])\n","    optimizer.load_state_dict([\"optimizer_state_dict\"])\n","    epoch=checkpoint[\"epoch\"]\n","    loss=checkpoint[\"loss\"]\n","    print(f\"‚úÖ Model loaded from {path}, Last Epoch: {epoch}, Loss: {loss:.4f}\")\n","\n","  else:\n","    print(\"‚ùå No saved model found!\")\n"],"metadata":{"id":"GXoZq2BSqduJ","executionInfo":{"status":"ok","timestamp":1738768471294,"user_tz":-300,"elapsed":676,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["def translate_sentence(sentence, src_vocab, tgt_vocab, model, device, max_length=50):\n","    model.eval()\n","\n","    # Tokenize input sentence\n","    tokens = [\"<bos>\"] + tokenize_de(sentence) + [\"<eos>\"]\n","    src_indices = [src_vocab.get(token, UNK_IDX) for token in tokens]\n","    src_tensor = torch.tensor(src_indices, dtype=torch.long).unsqueeze(0).to(device)\n","\n","    # Encode\n","    with torch.no_grad():\n","        hidden, cell = model.encoder(src_tensor)\n","\n","    # Decode\n","    tgt_indexes = [BOS_IDX]\n","    for _ in range(max_length):\n","        tgt_tensor = torch.tensor([tgt_indexes[-1]], dtype=torch.long).to(device)\n","        with torch.no_grad():\n","            output, hidden, cell = model.decoder(tgt_tensor, hidden, cell)\n","            pred_token = output.argmax(1).item()\n","\n","        tgt_indexes.append(pred_token)\n","        if pred_token == EOS_IDX:\n","            break\n","\n","    # Convert indexes to words\n","    tgt_tokens = [list(tgt_vocab.keys())[list(tgt_vocab.values()).index(idx)] for idx in tgt_indexes]\n","    return \" \".join(tgt_tokens[1:-1])  # Remove <bos> and <eos>\n","\n","# Example Usage:\n","sentence = \"Das kleine Kind klettert an roten Seilen auf einem Spielplatz.\"\n","translation = translate_sentence(sentence, src_vocab, tgt_vocab, model, device)\n","print(f\"üìù Translation: {translation}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w6LpLnzerU6G","executionInfo":{"status":"ok","timestamp":1738768846120,"user_tz":-300,"elapsed":1482,"user":{"displayName":"Waleed Usman","userId":"14222602887761143824"}},"outputId":"2f0195ba-4915-4e4e-ff39-d7a539e3a08d"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["üìù Translation: The little child is climbing a a slide on a playground .\n"]}]}]}